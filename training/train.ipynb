{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea12af0",
   "metadata": {},
   "source": [
    "# GNN Training\n",
    "\n",
    "This notebook trains a **Graph Neural Network (GNN)** with the `DirSAGEEmbRes` architecture, to predict next-hour subway ridership across MTA station complexes. \n",
    "`DirSAGEEmbRes` is used because it has direction-aware message passing, station-specific identity, and stable deep propagation. \n",
    "\n",
    "Ridership at a station depends on:\n",
    "- It's own history + time-of-day/day-of-week (temporal)\n",
    "- Nearby stations / connected lines (spatial spillover)\n",
    "- Directional effects (inflow and outflow of commuters)\n",
    "\n",
    "**Learnable Node Embeddings:**\n",
    "The architecture uses learnable node embeddings to give the model a trainable station identity vector, representing things like baseline demand (quiet vs busy stop), being a transfer hub, neighbourhood differences etc.\n",
    "\n",
    "**Two SAGEConv Layers:**\n",
    "Separate convolutions for incoming and outgoing edges. This lets the model learn different transformation weights for each direction. For example, a station might have many more incoming than outgoing riders in the morning (e.g. industrial areas) or have many more incoming than outgoing riders at night (e.g. residential areas). Using two SAGEConv streams allows for more expressive modelling of asymmetric flow patterns. Using two layers allows for a node to incorporate information from neighbours that are up to 2 hops away.\n",
    "\n",
    "**Residual Connections:**\n",
    "GNN stacks can often suffer from over-smoothing (node representations becoming too similar after multiple message passing steps) and harder optimisation (gradient fading, unstable training). Residuals help to preserve the node's original signal (its own ridership and embedding). They let each layer learn a correction instead of rewriting everythingm making it safe to stack layers without removing station identity. Over-smoothing is an even greater risk in this scenario since many stations are connected through short paths. Should embeddings lose their distinctness, the model may lose the ability to distinguish individual station dynamics. \n",
    "\n",
    "**ReLU Activation:**\n",
    "Clips all negative values to 0, leaves positive values unchanged. Without ReLU activation, stacking layers would still result in an effectively linear layer. This makes computation non-linear, so stacking layers increases what the model can represent. ReLU keeps positive signals, zeros negative signals, and introduces non-linearity before the next layer.\n",
    "\n",
    "**Key points:**\n",
    "- The NYC subway is modeled as a graph: stations are nodes, track connections are edges.\n",
    "- At each hour t, the model builds a station's representation from **station identity (embedding), current local state (ridership + time), neighbours's states (message passing) while not forgetting itself (residual)**. It uses this to predict ridership at t+1.\n",
    "- Information flows between connected stations, allowing the model to learn spatial and temporal patterns.\n",
    "\n",
    "**Data pipeline:**\n",
    "1. `preprocess.py` splits yearly CSVs into train/val/test parquet files and computes per-station normalization stats.\n",
    "2. This notebook loads those parquet files and trains the GNN model.\n",
    "\n",
    "**Split strategy (temporal, no data leakage):**\n",
    "- 2020–2022: train\n",
    "- 2023:      val\n",
    "- 2024:      test\n",
    "\n",
    "Stats are computed from training data to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fd7096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\setho\\ichack26\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3516e1",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5baa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "EPOCHS = 15       # Max number of passes through the full training set\n",
    "LR = 1e-4         # Learning rate for Adam optimizer\n",
    "HIDDEN_DIM = 64   # Size of the model's internal node representation after a message-passing layer. More -> model can learn more complex patterns, but slower training and higher risk of overfitting\n",
    "PATIENCE = 4      # Stop training if val loss doesn't improve for this many consecutive epochs\n",
    "\n",
    "# Paths\n",
    "ROOT = os.path.dirname(os.path.abspath(\"\"))\n",
    "PROC_DIR = os.path.join(ROOT, \"data\", \"processed\")\n",
    "MODEL_DIR = os.path.join(ROOT, \"new_models\")\n",
    "EDGES_PATH = os.path.join(PROC_DIR, \"ComplexEdges.csv\")\n",
    "CMPLX_PATH = os.path.join(PROC_DIR, \"ComplexNodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7ae52",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "The model used here is **DirSAGEEmbRes**, a custom GNN architecture. It is a directional SAGE variant.\n",
    "- Uses learnable node embeddings for each station.\n",
    "- Two SAGEConv layers for both incoming and outgoing edges.\n",
    "- Residual connections to reduce over-smoothing.\n",
    "- Final linear layer outputs the predicted next-hour normalized ridership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7071559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirSAGEEmbRes(nn.Module):\n",
    "    # Defining the layers\n",
    "    def __init__(self, num_nodes: int, in_dim: int, hidden_dim: int, emb_dim: int = 16):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Create a learnable table of vectors shaped [num_nodes, emb_dim]\n",
    "        Each node index i has its own trainable embedding vector node_emb[i]\n",
    "        Station identity features that the model learns\n",
    "        \"\"\"\n",
    "        self.node_emb = nn.Embedding(num_nodes, emb_dim)\n",
    "        # Effective input dimension to GNN = in_dim columns of input node features + emb_dim\n",
    "        d0 = in_dim + emb_dim\n",
    "        \n",
    "        \"\"\"\n",
    "        Incoming GraphSAGE layers\n",
    "        Message-passing layers that aggregate information from neighbours. Node features + edges -> output new node features\n",
    "        Layers run using edge_in\n",
    "        \"\"\"\n",
    "        self.in1 = SAGEConv(d0, hidden_dim)\n",
    "        self.in2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        Outgoing GraphSAGE layers\n",
    "        Layers run using edge_out\n",
    "        \"\"\"\n",
    "        self.out1 = SAGEConv(d0, hidden_dim)\n",
    "        self.out2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        At the end, concatenate the outputs of incoming and outgoing layers -> gives a vector of size 2 * hidden_dim for each node\n",
    "        Linear layer to produce final prediction from this concatenated vector.\n",
    "        \"\"\"\n",
    "        self.lin = nn.Linear(2 * hidden_dim, 1)\n",
    "\n",
    "    \"\"\"\n",
    "    x = node features matrix [num_nodes, in_dim]\n",
    "    edge_in, edge_out = edge index tensors for incoming and outgoing edges, shape [2, num_edges]\n",
    "    \"\"\"\n",
    "    def forward(self, x, edge_in, edge_out):\n",
    "        \"\"\"\n",
    "        Create node indices [0...num_nodes-1]\n",
    "        Used to look up embeddings for each node\n",
    "        device ensures that the indices are on the same device (CPU/GPU) as the input features\n",
    "        \"\"\"\n",
    "        node_ids = torch.arange(x.size(0), device=x.device)\n",
    "\n",
    "        \"\"\"\n",
    "        Concatenate input features with node embeddings\n",
    "        Each node now has real features (ridership/time) and a learnable station identity vector\n",
    "        \"\"\"\n",
    "        x = torch.cat([x, self.node_emb(node_ids)], dim=1)\n",
    "\n",
    "        # Incoming stream - message-passing layers using edge_in\n",
    "        h_in1 = torch.relu(self.in1(x, edge_in))     # For each node, gather neighbour features (message passing) using edges in edge_in, aggregate + transform into new representation, producing +ve/-ve numbers.\n",
    "                                                     # ReLU keeps positive signals and zeros negative signals.\n",
    "        h_in2 = torch.relu(self.in2(h_in1, edge_in)) # Repeat with second layer but now using learned representation from layer 1.\n",
    "        h_in  = h_in2 + h_in1                        # Add layer 1 and layer 2 outputs to get final incoming representation. \n",
    "        # Prevent 2nd layer from over-smoothing and losing information from layer 1, 2nd layer becomes a refinement. \n",
    "        # Shape: [num_nodes, hidden_dim]\n",
    "        \n",
    "        # Same but for outgoing stream\n",
    "        h_out1 = torch.relu(self.out1(x, edge_out))\n",
    "        h_out2 = torch.relu(self.out2(h_out1, edge_out))\n",
    "        h_out  = h_out2 + h_out1\n",
    "        # Shape: [num_nodes, hidden_dim]\n",
    "\n",
    "        # Concatenate in/out representations and predict\n",
    "        h = torch.cat([h_in, h_out], dim=-1)\n",
    "        # Shape: [num_nodes, 2 * hidden_dim]\n",
    "        # [num_nodes, 2 * hidden_dim] -> [num_nodes, 1] -> [num_nodes]\n",
    "        return self.lin(h).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c6467",
   "metadata": {},
   "source": [
    "## Load Graph Structure\n",
    "- **Node mapping** (`ComplexNodes.csv`): Maps station complex IDs to node indices for PyTorch.\n",
    "- **Edges** (`ComplexEdges.csv`): Pairs of connected stations. Both directions are included. Self-loops are added for stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54af2fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 424, Edge_in: 976, Edge_out: 976\n"
     ]
    }
   ],
   "source": [
    "# Load the station complex ID -> node index mapping\n",
    "cmplx_df = pd.read_csv(CMPLX_PATH)\n",
    "ComplexNodes = dict(zip(cmplx_df[\"complex_id\"], cmplx_df[\"node_id\"]))\n",
    "\n",
    "num_nodes = len(ComplexNodes)\n",
    "\n",
    "# Load edges\n",
    "edges_df = pd.read_csv(EDGES_PATH)\n",
    "\n",
    "edge_in_list = []   # from -> to\n",
    "edge_out_list = []  # to -> from\n",
    "\n",
    "for _, row in edges_df.iterrows():\n",
    "    s, e = row[\"from_complex_id\"], row[\"to_complex_id\"]\n",
    "    if s in ComplexNodes and e in ComplexNodes:\n",
    "        sn, en = ComplexNodes[s], ComplexNodes[e]\n",
    "        edge_in_list.append([sn, en])\n",
    "        edge_out_list.append([en, sn])\n",
    "\n",
    "# Add self-loops (each node is connected to itself)\n",
    "for i in range(num_nodes):\n",
    "    edge_in_list.append([i, i])\n",
    "    edge_out_list.append([i, i])\n",
    "\n",
    "# edge_in_list, edge_out_list are lists of [from_node, to_node] pairs for each edge, including self-loops.\n",
    "# edge_in_list = [[u1,v1], [u2,v2], ..., [i,i], ...]\n",
    "\n",
    "# Convert lists of edges into a tensor of integers with shape [num_edges, 2], then transpose to shape [2, num_edges]\n",
    "# PyTorch Geometric expects edge_index as row 0 = from_node, row 1 = to_node\n",
    "# v aggregates messages from its incoming edges, u1, u2, ... are the source nodes sending messages to v\n",
    "edge_in = torch.tensor(edge_in_list, dtype=torch.long).T\n",
    "edge_out = torch.tensor(edge_out_list, dtype=torch.long).T\n",
    "\n",
    "print(f\"Nodes: {num_nodes}, Edge_in: {edge_in.shape[1]}, Edge_out: {edge_out.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b65df72",
   "metadata": {},
   "source": [
    "## Build Graph Snapshots\n",
    "\n",
    "Build (feature, target) pairs from consecutive timestamps.\n",
    "Each snapshot is one supervised training example: features at hour t, target at hour t+1\n",
    "\n",
    "For every pair of consecutive hours in the data:\n",
    "- Input (X): a matrix of shape `(num_nodes, 5)` for each station:\n",
    "  - `ridership_norm`: z-score normalized ridership at time $t$\n",
    "  - `sin_hour`, `cos_hour`: sine/cosine encoding of the hour\n",
    "  - `sin_dow`, `cos_dow`: sine/cosine encoding of the day of week\n",
    "- Target (y): normalized ridership at time $t+1$ for each station\n",
    "\n",
    "The graph edges are defined in terms of node indices, so the feature tensor must use the same indexing scheme. Some timestamps might be missing certain stations, use a dense tensor to represent a missing station row as all zeros. \n",
    "\n",
    "This setup enables the model to learn both temporal and spatial dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_snapshots(df, num_nodes):\n",
    "    \"\"\"\n",
    "    Build (features, targets) pairs from consecutive timestamps.\n",
    "\n",
    "    Each snapshot is one supervised training example:\n",
    "    - features at hour t: [ridership_norm, sin_hour, cos_hour, sin_dow, cos_dow]\n",
    "    - targets at hour t+1: [ridership_norm]\n",
    "    \"\"\"\n",
    "    # Split df into groups by timestamp\n",
    "    groups = {t: g for t, g in df.groupby(\"transit_timestamp\")}\n",
    "    timestamps = sorted(groups.keys())\n",
    "\n",
    "    # List of X and y tensors (one per t -> t+1 pair)\n",
    "    features = []\n",
    "    targets = []\n",
    "\n",
    "    # Iterate through consecutive timestamp pairs (t, t+1), zip(all except last, all except first)\n",
    "    for t0, t1 in zip(timestamps[:-1], timestamps[1:]):\n",
    "\n",
    "        # Only consider pairs that are one hour apart\n",
    "        if (t1 - t0).total_seconds() > 3600:\n",
    "            continue\n",
    "\n",
    "        # Rows for time t0 and t1\n",
    "        g0 = groups[t0]\n",
    "        g1 = groups[t1]\n",
    "\n",
    "        # Allocate dense, node-aligned tensors\n",
    "        # X: features at time t0, y: target at time t1\n",
    "        X = torch.zeros(num_nodes, 5)\n",
    "        y = torch.zeros(num_nodes)\n",
    "\n",
    "        # Node indices at each timestamp, for scattering values into tensors)\n",
    "        # idx0 -> which row in X corresponds to the stations in time t0\n",
    "        # idx1 -> which row in y corresponds to the stations in time t1\n",
    "        idx0 = torch.tensor(g0[\"node_id\"].values)\n",
    "        idx1 = torch.tensor(g1[\"node_id\"].values)\n",
    "\n",
    "        # Fill X rows for nodes at t0, y for nodes at t1\n",
    "        X[idx0, 0] = torch.tensor(g0[\"ridership_norm\"].values.astype(np.float32))\n",
    "        X[idx0, 1] = torch.tensor(g0[\"sin_hour\"].values.astype(np.float32))\n",
    "        X[idx0, 2] = torch.tensor(g0[\"cos_hour\"].values.astype(np.float32))\n",
    "        X[idx0, 3] = torch.tensor(g0[\"sin_dow\"].values.astype(np.float32))\n",
    "        X[idx0, 4] = torch.tensor(g0[\"cos_dow\"].values.astype(np.float32))\n",
    "        y[idx1] = torch.tensor(g1[\"ridership_norm\"].values.astype(np.float32))\n",
    "\n",
    "        # Store (X_t, y_t+1) pair\n",
    "        features.append(X)\n",
    "        targets.append(y)\n",
    "\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a17a0",
   "metadata": {},
   "source": [
    "## Load Training Data\n",
    "\n",
    "The training parquet contains all 2020–2022 data. Each row has one station's ridership at one timestamp, already normalized and with time encodings computed by `preprocess.py`.\n",
    "\n",
    "The data is converted into a list of graph snapshots, each representing a pair of consecutive hours for all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364d52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 10,522,218\n",
      "Train snapshots: 26273\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed training data\n",
    "train_df = pd.read_parquet(os.path.join(PROC_DIR, \"train.parquet\"))\n",
    "print(f\"Train rows: {len(train_df):,}\")\n",
    "\n",
    "# Convert the df into a list of graph snapshots (one per consecutive hour pair)\n",
    "train_features, train_targets = build_snapshots(train_df, num_nodes)\n",
    "print(f\"Train snapshots: {len(train_features)}\")\n",
    "\n",
    "# Free memory, only the snapshot tensors are needed\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91814a44",
   "metadata": {},
   "source": [
    "## Load Validation Data\n",
    "\n",
    "The validation set is 2023. Used to detect overfitting. Validation data is also converted into graph snapshots for evaluation after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf2af59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val rows: 3,639,413\n",
      "Val snapshots: 8757\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.read_parquet(os.path.join(PROC_DIR, \"val.parquet\"))\n",
    "print(f\"Val rows: {len(val_df):,}\")\n",
    "\n",
    "val_features, val_targets = build_snapshots(val_df, num_nodes)\n",
    "print(f\"Val snapshots: {len(val_features)}\")\n",
    "\n",
    "# Free memory, only the snapshot tensors are needed\n",
    "del val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccda2cc",
   "metadata": {},
   "source": [
    "## Initialize Model\n",
    "\n",
    "- **DirSAGEEmbRes**: Graph neural network with node embeddings, two SAGEConv layers for incoming and outgoing edges, and residual connections to reduce over-smoothing.\n",
    "- **Adam optimizer**: Adaptive learning rate optimiser, automatically scales weights using running estimates. Adjusts step size per parameter. Requires less tuning, works better out-of-the-box.\n",
    "- **MSE loss**: Penalise large errors more, training focuses on reducing large errors. \n",
    "- **Model checkpointing**: Best model (lowest validation loss) is saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57df791d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 28,929\n",
      "Will save best model to: c:\\Users\\setho\\PersonalProjects\\hush\\new_models\\model.pt\n"
     ]
    }
   ],
   "source": [
    "# Create the model with 5 input features and hidden layers\n",
    "model = DirSAGEEmbRes(num_nodes=num_nodes, in_dim=5, hidden_dim=HIDDEN_DIM, emb_dim=16)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "best_model_path = os.path.join(MODEL_DIR, \"model.pt\")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Will save best model to: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bcc6af",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "**Early stopping:**\n",
    "1. After each epoch, validation loss is checked.\n",
    "2. If val loss improves, the model checkpoint is saved. This saves the best model so far\n",
    "3. If val loss doesn't improve for `PATIENCE` consecutive epochs, training stops early to prevent overfitting.\n",
    "\n",
    "Ensures that the best model is saved. Avoids overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa02ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch   Train Loss     Val Loss      Status\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1      0.176997     0.179397     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2      0.090805     0.154851     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3      0.079282     0.140128     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4      0.073461     0.129812     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5      0.069737     0.123689     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     6      0.067052     0.118758     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     7      0.065047     0.114990     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     8      0.063570     0.111564     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9      0.062494     0.109464     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10      0.061086     0.107900     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    11      0.059882     0.106413     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    12      0.058819     0.105219     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    13      0.057855     0.103947     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    14      0.057011     0.103017     ★ saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15      0.056299     0.102236     ★ saved\n",
      "\n",
      "Best val loss: 0.102236\n",
      "Model saved:   c:\\Users\\setho\\PersonalProjects\\hush\\new_models\\model.pt\n"
     ]
    }
   ],
   "source": [
    "# Track best validation loss\n",
    "best_val_loss = float(\"inf\")\n",
    "patience_counter = 0  # Epochs since last improvement\n",
    "\n",
    "print(f\"{'Epoch':>6}  {'Train Loss':>11}  {'Val Loss':>11}  {'Status':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Epoch = one full pass through all training snapshots.\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()         # Put model in training mode (enables dropout/batchnorm, not used here)\n",
    "    total_train_loss = 0  # Accumulate mean training loss over the epoch\n",
    "    \n",
    "    # TRAINING\n",
    "    # Loop through every snapshot: input hour t, predict hour t+1, update weights\n",
    "    for X, y in tqdm(zip(train_features, train_targets), total=len(train_features), desc=f\"Epoch {epoch}\", leave=False):\n",
    "        optimizer.zero_grad()               # Clear old gradients\n",
    "        y_hat = model(X, edge_in, edge_out) # Forward pass: Returns one prediction per node for time t+1\n",
    "        loss = loss_fn(y_hat, y)            # Compute loss by comparing predictions to true targets for time t+1\n",
    "        loss.backward()                     # Backpropagation: Compute gradients of loss wrt every parameter\n",
    "        optimizer.step()                    # Update parameters using gradients and learning rate\n",
    "        total_train_loss += loss.item()     # Accumulate loss for this snapshot\n",
    "    train_loss = total_train_loss / len(train_features)\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval() # Put model in eval mode (disables dropout/batchnorm, not used here)\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient tracking, do not accidentally backprop during validation, uses less memory\n",
    "        for X, y in zip(val_features, val_targets):\n",
    "            y_hat = model(X, edge_in, edge_out) # Compute prediction \n",
    "            loss = loss_fn(y_hat, y)            # Compute MSE\n",
    "            total_val_loss += loss.item()       # Average loss\n",
    "    val_loss = total_val_loss / len(val_features)\n",
    "\n",
    "    # EARLY STOPPING CHECK\n",
    "    if val_loss < best_val_loss:\n",
    "        # New best validation performance, save model weights and reset patience counter\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        status = \"saved\"\n",
    "    else:\n",
    "        # No improvement, increment patience counter\n",
    "        patience_counter += 1\n",
    "        status = f\"wait {patience_counter}/{PATIENCE}\"\n",
    "\n",
    "    print(f\"  {epoch:>4}   {train_loss:>11.6f}  {val_loss:>11.6f}  {status:>10}\")\n",
    "\n",
    "    # val loss has not improved for PATIENCE consecutive epochs, stop training to avoid overfitting and wasting time\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch} (no improvement for {PATIENCE} epochs)\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nBest val loss: {best_val_loss:.6f}\")\n",
    "print(f\"Model saved:   {best_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
